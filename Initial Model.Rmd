---
title: "Initial Model"
author: "Rick Morales"
date: "`r Sys.Date()`"
output: pdf_document
---

# Libraries
```{r}
library(haven)
library(dplyr)
library(mice) # For imputation
library(tidyverse)
library(caret)
library(parameters)
library(see)
library(lmtest)  # For assumption testing
library(ggplot2)
library(car)  # For Variance Inflation Factor (VIF)
library(ordinalNet)
library(plyr)
library(smotefamily)
library(MASS)
library(MLmetrics)
library(ipred)
library(rpart)
library(pROC)
library(randomForest)
library(mice)
library(tidyr)
library(PRROC)

brfss_2017 <- read_xpt("LLCP2017.XPT")

head(brfss_2017)

colnames(brfss_2017)
```


# Cleaned Data
```{r}
brfss_2017_cleaned <- brfss_2017 %>%
    dplyr::select(-c(2:6), -c(10:27), -31, -37, -40, -45, -c(53:57), -c(62:64), -72, -c(80:82), -85, -c(87:89), -c(97:102), -106, -108, -110, -c(112:246), ... = -c(255:258), -c(326:327), -c(330:337), -c(340:345), -c(356:357))

head(brfss_2017_cleaned)
```


# Renamed For Clarity
```{r}
names(brfss_2017_cleaned)[1] <- "STATE"
names(brfss_2017_cleaned)[4] <- "PSU"
names(brfss_2017_cleaned)[8] <- "HLTHPLN"
names(brfss_2017_cleaned)[9] <- "PERSDOC"
names(brfss_2017_cleaned)[11] <- "CHECKUP"
names(brfss_2017_cleaned)[12] <- "BPHIGH"
names(brfss_2017_cleaned)[13] <- "CHOLCHK"
names(brfss_2017_cleaned)[14] <- "TOLDHI"
names(brfss_2017_cleaned)[15] <- "CVDINFR"
names(brfss_2017_cleaned)[16] <- "CVDCRHD"
names(brfss_2017_cleaned)[17] <- "CVDSTRK"
names(brfss_2017_cleaned)[18] <- "ASTHMA"
names(brfss_2017_cleaned)[21] <- "CHCCOPD"
names(brfss_2017_cleaned)[22] <- "HAVARTH"
names(brfss_2017_cleaned)[23] <- "ADDEPEV"
names(brfss_2017_cleaned)[25] <- "DIABETES"
names(brfss_2017_cleaned)[29] <- "RENTHOME"
names(brfss_2017_cleaned)[30] <- "VETERAN"
names(brfss_2017_cleaned)[31] <- "EMPLOYED"
names(brfss_2017_cleaned)[33] <- "INCOME"
names(brfss_2017_cleaned)[35] <- "WEIGHT"
names(brfss_2017_cleaned)[36] <- "HEIGHT"
names(brfss_2017_cleaned)[44] <- "USENOW"
names(brfss_2017_cleaned)[47] <- "FRUIT"
names(brfss_2017_cleaned)[48] <- "FRUIT_JUICE"
names(brfss_2017_cleaned)[49] <- "GREEN_VEG"
names(brfss_2017_cleaned)[50] <- "FRENCHF"
names(brfss_2017_cleaned)[51] <- "POTATO"
names(brfss_2017_cleaned)[52] <- "OTHER_VEG"
names(brfss_2017_cleaned)[53] <- "EXERCISE_ANY"
names(brfss_2017_cleaned)[56] <- "FLUSHOT"
names(brfss_2017_cleaned)[57] <- "PNEUMONIA_VAC"
names(brfss_2017_cleaned)[58] <- "HIVTEST"
names(brfss_2017_cleaned)[59] <- "HIVRISK"
names(brfss_2017_cleaned)[63] <- "STSTR"
names(brfss_2017_cleaned)[64] <- "STRATUM_WGHT"
names(brfss_2017_cleaned)[65] <- "RAWRAKE"
names(brfss_2017_cleaned)[66] <- "WT2RAKE"
names(brfss_2017_cleaned)[67] <- "IMPRACE"
names(brfss_2017_cleaned)[68] <- "DUALUSE"
names(brfss_2017_cleaned)[69] <- "DUALCOR"
names(brfss_2017_cleaned)[70] <- "LLCPWT2"
names(brfss_2017_cleaned)[71] <- "LLCPWT"
names(brfss_2017_cleaned)[72] <- "RFHLTH"
names(brfss_2017_cleaned)[73] <- "PHYS_COMP"
names(brfss_2017_cleaned)[74] <- "MENT_COMP"
names(brfss_2017_cleaned)[75] <- "HCVU651"
names(brfss_2017_cleaned)[76] <- "RFHYPES"
names(brfss_2017_cleaned)[77] <- "CHOLCH1"
names(brfss_2017_cleaned)[78] <- "HICHOL_COMP"
names(brfss_2017_cleaned)[79] <- "MI_CHD"
names(brfss_2017_cleaned)[80] <- "ASTHMA_LIFE"
names(brfss_2017_cleaned)[81] <- "ASTHMA_NOW_COMP"
names(brfss_2017_cleaned)[82] <- "ASTHMA_COMP"
names(brfss_2017_cleaned)[83] <- "ARTHRITIS_DIAGNOS"
names(brfss_2017_cleaned)[84] <- "LIMIT_ACTIVITY"
names(brfss_2017_cleaned)[85] <- "LIMIT_WORK"
names(brfss_2017_cleaned)[86] <- "LIMIT_SOCIAL"
names(brfss_2017_cleaned)[87] <- "PRACE_COMP"
names(brfss_2017_cleaned)[88] <- "MULTI_RACE"
names(brfss_2017_cleaned)[89] <- "HISPANIC_COMP"
names(brfss_2017_cleaned)[90] <- "RACE_COMP"
names(brfss_2017_cleaned)[91] <- "RACEG21"
names(brfss_2017_cleaned)[92] <- "RACEGR3"
names(brfss_2017_cleaned)[93] <- "RACE_G1"
names(brfss_2017_cleaned)[94] <- "AGEG5YR"
names(brfss_2017_cleaned)[95] <- "AGE65YR"
names(brfss_2017_cleaned)[96] <- "AGE80"
names(brfss_2017_cleaned)[97] <- "AGE_G"
names(brfss_2017_cleaned)[98] <- "HT_COMP_IN"
names(brfss_2017_cleaned)[99] <- "HT_COMP_M"
names(brfss_2017_cleaned)[100] <- "WT_COMP_KILO"
names(brfss_2017_cleaned)[101] <- "BMI"
names(brfss_2017_cleaned)[102] <- "BMI_CAT"
names(brfss_2017_cleaned)[103] <- "BMI_OVER"
names(brfss_2017_cleaned)[104] <- "CHILD_COMP"
names(brfss_2017_cleaned)[105] <- "EDUCA_COMP"
names(brfss_2017_cleaned)[106] <- "INCOME_COMP"
names(brfss_2017_cleaned)[107] <- "SMOKER_COMP"
names(brfss_2017_cleaned)[108] <- "SMOKENOW_COMP"
names(brfss_2017_cleaned)[109] <- "ECIG_COMP"
names(brfss_2017_cleaned)[110] <- "ECIG_NOW_COMP"
names(brfss_2017_cleaned)[111] <- "DRINKANY_30"
names(brfss_2017_cleaned)[112] <- "DROCDY3"
names(brfss_2017_cleaned)[113] <- "BINGE_COMP"
names(brfss_2017_cleaned)[114] <- "WEEKLY_DRINK"
names(brfss_2017_cleaned)[115] <- "HEAVY_DRINK"
names(brfss_2017_cleaned)[116] <- "FRUITJUICE_COMP"
names(brfss_2017_cleaned)[117] <- "FRUITJUICE_COMP2"
names(brfss_2017_cleaned)[118] <- "GREEN_VEG_COMP"
names(brfss_2017_cleaned)[119] <- "FRENCHF_COMP"
names(brfss_2017_cleaned)[120] <- "POTATO_COMP"
names(brfss_2017_cleaned)[121] <- "OTHER_VEG_COMP"
names(brfss_2017_cleaned)[122] <- "MISSING_FRUIT"
names(brfss_2017_cleaned)[123] <- "MISSING_VEG"
names(brfss_2017_cleaned)[124] <- "MISS_ANY_FRUIT"
names(brfss_2017_cleaned)[125] <- "MISS_ANY_VEG"
names(brfss_2017_cleaned)[126] <- "TOTAL_FRUIT"
names(brfss_2017_cleaned)[127] <- "TOTAL_VEG"
names(brfss_2017_cleaned)[128] <- "ATLEAST1_FRUIT"
names(brfss_2017_cleaned)[129] <- "ATLEAST1_VEG"
names(brfss_2017_cleaned)[130] <- "MORE16_FRUIT"
names(brfss_2017_cleaned)[131] <- "MORE23_VEG"
names(brfss_2017_cleaned)[132] <- "FRUIT_EXCLUDE"
names(brfss_2017_cleaned)[133] <- "VEG_EXCLUDE"
names(brfss_2017_cleaned)[134] <- "LEISURE_COMP"
names(brfss_2017_cleaned)[135] <- "MAX_OXYGEN"
names(brfss_2017_cleaned)[136] <- "FUNC_CAPACITY"
names(brfss_2017_cleaned)[137] <- "STRENGTH_FREQ"
names(brfss_2017_cleaned)[138] <- "MISSING_PHYS"
names(brfss_2017_cleaned)[139] <- "PHYS_CATEGORY"
names(brfss_2017_cleaned)[140] <- "PHYS_IDX"
names(brfss_2017_cleaned)[141] <- "150_PHYS_COMP"
names(brfss_2017_cleaned)[142] <- "300_PHYS_COMP"
names(brfss_2017_cleaned)[143] <- "300_PHYS2_COMP"
names(brfss_2017_cleaned)[144] <- "MUSCLE_RECOMMEND"
names(brfss_2017_cleaned)[145] <- "AEROBIC_STRENGTH"
names(brfss_2017_cleaned)[146] <- "AEROBIC_STRENGTH2"
names(brfss_2017_cleaned)[147] <- "SEATBELT_COMP"
names(brfss_2017_cleaned)[148] <- "SEATBELT_COMP2"
names(brfss_2017_cleaned)[149] <- "AIDSTEST_COMP"

head(brfss_2017_cleaned)
```

# Drop source variables and target leakage risks
```{r}
# Remove certain calculated variables
brfss_2017_cleaned <- brfss_2017_cleaned %>%
  dplyr::select(-c(35, 36, 43, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149))

# For calculated variables with values of 9, change values to NA
#brfss_2017_cleaned %>%
  #  select(ECIG_COMP, SMOKER_COMP) %>%
   # mutate(ECIG_COMP = na_if(ECIG_COMP, 9)) %>%
   # mutate(SMOKER_COMP = na_if(SMOKER_COMP, 9))

#brfss_2017_cleaned %>%
   # mutate(ECIG_COMP = replace(ECIG_COMP, ECIG_COMP == "9", NA))
brfss_2017_cleaned$ECIG_COMP[brfss_2017_cleaned$ECIG_COMP == 9] <- NA
brfss_2017_cleaned$SMOKER_COMP[brfss_2017_cleaned$SMOKER_COMP == 9] <- NA

# Remove SEQNO since it's a unique identifier
brfss_2017_cleaned <- brfss_2017_cleaned %>%
    dplyr::select(-c(SEQNO))

# Filter for only asthmatics
brfss_2017_cleaned <- brfss_2017_cleaned %>%
  filter(ASTHMA == 1)

# Ensure unique column names
colnames(brfss_2017_cleaned) <- make.names(colnames(brfss_2017_cleaned), unique = TRUE)

# Correlation for all variables
round(cor(brfss_2017_cleaned), digits = 2)

# Create model for VIF
vif_model <- lm(ECIG_COMP ~ AGE80 + BMI + SMOKER_COMP + STATE + ADDEPEV + ALCDAY5 + CHCCOPD + CHECKUP + EDUCA + GENHLTH + HLTHPLN + INCOME + SEX, data = brfss_2017_cleaned)

# Calculating VIF
vif_values <- vif(vif_model)
vif_values

# Visualizing the model
plot(vif_model, which = 1, main = "Model Fit")

# Visualizing VIF
barplot(vif_values, las = 2, col = "skyblue", main = "Variance Inflation Factor (VIF)")

# Creating a correlation matrix
cor_matrix <- cor(brfss_2017_cleaned[c('AGE80', 'BMI', 'SMOKER_COMP', 'STATE', 'ADDEPEV', 'ALCDAY5',
                    'CHCCOPD', 'CHECKUP', 'EDUCA', 'GENHLTH', 'HLTHPLN', 'INCOME', 'SEX')])

# Visualizing the correlation matrix
image(cor_matrix, main = "Correlation Matrix", col = colorRampPalette(c("blue", "white", "red"))(20))
```
Binary Random Forest Model

Train-Test Split for Binary (filtered on asthmatics)
```{r}
# Binary Variable Creation
df <- brfss_2017_cleaned

# Filter for Adult Asthmatics who Smoke
  df <- brfss_2017_cleaned %>%
      filter(
          ECIG_COMP != 4,
          ASTHMA == 1
          )

df$ECIG_BINARY <- ifelse(df$ECIG_COMP == 1 | df$ECIG_COMP == 2, 1, 0)
df$ECIG_COMP <- as.factor(df$ECIG_COMP)
df$ECIG_BINARY <- as.factor(df$ECIG_BINARY)
df$STATE <- as.numeric(as.character(df$STATE))
set.seed(1)
split_bin <- createDataPartition(df$ECIG_BINARY, times = 1, p = .7, list = FALSE)
train_bin <- df[split_bin, ]
test_bin <- df[-split_bin, ]
```

Train_test Split for Binary (no filter)
```{r}
# Binary Variable Creation
df_nf <- brfss_2017_cleaned

df_nf$ECIG_BINARY <- ifelse(df_nf$ECIG_COMP == 1 | df_nf$ECIG_COMP == 2, 1, 0)
df_nf$ECIG_COMP <- as.factor(df_nf$ECIG_COMP)
df_nf$ECIG_BINARY <- as.factor(df_nf$ECIG_BINARY)
df_nf$STATE <- as.numeric(as.character(df_nf$STATE))
set.seed(1)
split_bin_nf <- createDataPartition(df_nf$ECIG_BINARY, times = 1, p = .7, list = FALSE)
train_bin_nf <- df_nf[split_bin_nf, ]
test_bin_nf <- df_nf[-split_bin_nf, ]
```

# Imputation of Missing Values ECIG_BIN for Asthmatics

Survey data assumes missing values are classified as missing at random. Multiple imputation by chained equations. Best for survey data. Method chosen is cart (imputation by classification and regression trees)
```{r}
# Calculate imputed values with training data
methods(mice)
#seed = 10 for Asthmatics, seed = 11 without filter
imp_bin <- mice(train_bin, method = "cart", m = 1, maxit = 1, seed = 11)

train_bin <- complete(imp_bin)
#imputed_values <- mice(train, method = "rf)
```
```{r}
# Calculate imputed values with training data
methods(mice)
#seed = 10 for Asthmatics, seed = 11 without filter
imp_bin_nf <- mice(train_bin_nf, method = "cart", m = 1, maxit = 1, seed = 12)

train_bin_nf <- complete(imp_bin_nf)
```

Class Imbalance Check for Asthmatics
```{r}
ggplot(train_bin, aes(x = as.factor(ECIG_BINARY), 
                      y = prop.table(stat(count)),
                      fill = as.factor(ECIG_BINARY),
                      label = scales::percent(prop.table(stat(count))))) + 
    geom_bar(position = "dodge") +
    geom_text(stat = 'count',
              position = position_dodge(.10),
              vjust = -0.5,
              size = 4) +
    scale_y_continuous(labels = scales::percent) +
    scale_x_discrete(labels = c('Never Used', 'Used')) + 
    labs(title = "E-Cigarette Smoking Status Among Those with History of Asthma in 2017", x = "E-Cig Smoking Status", y = "Surveyed Population %", fill = "E-Cig Smoking Status")

```
Class Imbalance Check not filtered
```{r}
ggplot(train_bin_nf, aes(x = as.factor(ECIG_BINARY), 
                      y = prop.table(stat(count)),
                      fill = as.factor(ECIG_BINARY),
                      label = scales::percent(prop.table(stat(count))))) + 
    geom_bar(position = "dodge") +
    geom_text(stat = 'count',
              position = position_dodge(.10),
              vjust = -0.5,
              size = 4) +
    scale_y_continuous(labels = scales::percent) +
    scale_x_discrete(labels = c('Never Used', 'Used')) + 
    labs(title = "E-Cigarette Smoking Status Among Those with History of Asthma in 2017", x = "E-Cig Smoking Status", y = "Surveyed Population %", fill = "E-Cig Smoking Status")
```

Predictor and Target Setup Asthmatics
```{r}
# Use BMI_COMP instead of BMI
predictors <- c("AGE80", "BMI", "SMOKER_COMP", "STATE", "ADDEPEV",
                "CHCCOPD", "CHECKUP", "GENHLTH", "HLTHPLN",
                "EDUCA", "INCOME", "SEX", "ALCDAY5")

# Convert factor predictors to numeric if needed
train_bin[predictors] <- lapply(train_bin[predictors], function(col) {
  if (is.factor(col)) suppressWarnings(as.numeric(as.character(col))) else col
})

train_bin <- train_bin %>%
  filter(if_any(all_of(predictors), ~ !is.na(.) & is.finite(.)))

# Create predictor matrix
x <- data.matrix(train_bin[, predictors])

# Target
y <- train_bin$ECIG_BINARY

# Final modeling data frame
data_rf <- data.frame(x, y)
```

Predictor and Target Setup not filtered
```{r}
# Convert factor predictors to numeric if needed
train_bin_nf[predictors] <- lapply(train_bin_nf[predictors], function(col) {
  if (is.factor(col)) suppressWarnings(as.numeric(as.character(col))) else col
})

train_bin_nf <- train_bin_nf %>%
  filter(if_any(all_of(predictors), ~ !is.na(.) & is.finite(.)))

# Create predictor matrix
x_nf <- data.matrix(train_bin_nf[, predictors])

# Target
y_nf <- train_bin_nf$ECIG_BINARY

# Final modeling data frame
data_rf_nf <- data.frame(x_nf, y_nf)
```


Random Forest Model + ROC/AUC Asthmatics
```{r}
# Convert outcome to factor for classification
train_bin$ECIG_BINARY <- factor(ifelse(train_bin$ECIG_COMP == 1 | train_bin$ECIG_COMP == 2, 1, 0))

# Train Random Forest model
#set.seed(12345678)
set.seed(10)
rf_model <- randomForest(
  x = train_bin[, predictors],
  y = train_bin$ECIG_BINARY,
  ntree = 1000,          # number of trees
  mtry = 2,              # number of variables per split (can tune)
  nodesize = 4,
  importance = TRUE
)

# Check model summary
print(rf_model)
```


```{r}
# Convert outcome to factor for classification
train_bin_nf$ECIG_BINARY <- factor(ifelse(train_bin_nf$ECIG_COMP == 1 | train_bin_nf$ECIG_COMP == 2, 1, 0))

# Train Random Forest model
#set.seed(12345678)
set.seed(10)
rf_model_nf <- randomForest(
  x = train_bin_nf[, predictors],
  y = train_bin_nf$ECIG_BINARY,
  ntree = 1000,          # number of trees
  mtry = 2,              # number of variables per split (can tune)
  nodesize = 4,
  importance = TRUE
)

# Check model summary
print(rf_model_nf)
```


1st Random Forest ROC & AUC
```{r}
# Predicted probabilities
rf_probs <- predict(rf_model, type = "prob")[, 2]  # probability of class "1"

# ROC curve
rf_roc <- roc(as.numeric(as.character(train_bin$ECIG_BINARY)), rf_probs)

# AUC
auc(rf_roc)

# Plot ROC
plot(rf_roc, col = "forestgreen", lwd = 2, main = "Random Forest ROC Curve")
abline(a = 0, b = 1, lty = 2, col = "red")
```

```{r}
# Predicted probabilities
rf_probs_nf <- predict(rf_model_nf, type = "prob")[, 2]  # probability of class "1"

# ROC curve
rf_roc_nf <- roc(as.numeric(as.character(train_bin_nf$ECIG_BINARY)), rf_probs_nf)

# AUC
auc(rf_roc_nf)

# Plot ROC
plot(rf_roc_nf, col = "forestgreen", lwd = 2, main = "Random Forest ROC Curve")
abline(a = 0, b = 1, lty = 2, col = "red")
```
Hyperparameter Tuning (Asthmatics)
```{r}
set.seed(12)
tuned_model <- tuneRF(
    x = train_bin[, predictors],
    y = train_bin$ECIG_BINARY,
    ntreeTry = 1000,
    mtryStart = 3,
    stepFactor = 1.5,
    improve = 0.01,
    trace = FALSE
)
```

Hyperparameter Tuning (no filter)
```{r}
set.seed(11)
tuned_model_nf <- tuneRF(
    x = train_bin_nf[, predictors],
    y = train_bin_nf$ECIG_BINARY,
    ntreeTry = 1000,
    mtryStart = 3,
    stepFactor = 1.5,
    improve = 0.01,
    trace = FALSE
)
```

Addressing Class Imbalance and Overfitting (Asthmatics)
```{r}
# Rename the factor levels
y <- factor(train_bin$ECIG_BINARY, levels = c("0", "1"), labels = c("No", "Yes"))

# Combine x_train and y_train into one data frame
data_rf <- data.frame(x, y)

#12 for asthmatics
set.seed(12)
ctrl_bin <- trainControl(method = "cv", #cross validation
                         number = 5, # 5 folds
                         sampling = "smote",
                         classProbs = TRUE,
                         summaryFunction = twoClassSummary)

randForMod <- train(y ~ .,
                       data = data_rf,
                       method = "rf",
                       trControl = ctrl_bin)

randForMod
```
Addressing Class Imbalance and Overfitting (no filter)
```{r}
# Rename the factor levels
y_nf <- factor(train_bin_nf$ECIG_BINARY, levels = c("0", "1"), labels = c("No", "Yes"))

# Combine x_train and y_train into one data frame
data_rf_nf <- data.frame(x_nf, y_nf)

#11
set.seed(11)
ctrl_bin_nf <- trainControl(method = "cv", #cross validation
                         number = 5, # 5 folds
                         sampling = "smote",
                         classProbs = TRUE,
                         summaryFunction = twoClassSummary)

randForMod_nf <- train(y_nf ~ .,
                    data = data_rf_nf,
                    method = "rf",
                    trControl = ctrl_bin_nf)

randForMod_nf
```
Feature Importance (Asthmatics)
```{r}
plot(randForMod)
varImpPlot(rf_model, main = "Variable Importance (Random Forest)", pch = 19, col = "black")
```
Feature Importance (No filter)
```{r}
plot(randForMod_nf)
varImpPlot(rf_model_nf, main = "Variable Importance (Random Forest)", pch = 19, col = "black")
```


Predicting Test Data (Asthmatics)
```{r}
predictor_vars <- c('AGE80', 'BMI', 'SMOKER_COMP', 'STATE', 'ADDEPEV', 'ALCDAY5',
                    'CHCCOPD', 'CHECKUP', 'EDUCA', 'GENHLTH', 'HLTHPLN', 'INCOME', 'SEX')

test_rand_pred <- predict(randForMod, test_bin)
#postResample(pred = rand_pred, obs = test_bin$ECIG_BINARY)
test_bin_prob <- predict(randForMod, test_bin, type = "prob")
```

Predicting Test Data (no filter)
```{r}
test_rand_pred_nf <- predict(randForMod_nf, test_bin_nf)
#postResample(pred = rand_pred, obs = test_bin$ECIG_BINARY)
test_bin_prob_nf <- predict(randForMod_nf, test_bin_nf, type = "prob")
```

Asthmatics
```{r}
# Filter test_bin to only rows with complete predictor values
test_bin_clean <- test_bin %>%
  filter(if_all(all_of(predictor_vars), ~ !is.na(.) & is.finite(.)))

# Predict probabilities
predict_prob <- predict(randForMod, newdata = test_bin_clean, type = "prob")

# Convert ECIG_BINARY to numeric labels (0 or 1)
weights <- as.numeric(as.character(test_bin_clean$ECIG_BINARY) == "1")

# Combine and drop NAs
pr_data <- data.frame(prob = predict_prob[, 2], label = weights)
pr_data <- pr_data[complete.cases(pr_data), ]

# Run PR Curve
pr <- pr.curve(scores.class0 = pr_data$prob,
               weights.class0 = pr_data$label,
               curve = TRUE)

# Plot it
plot(pr)

pr$auc.integral  # This is your PR-AUC score

```
No filter
```{r}
# Filter test_bin to only rows with complete predictor values
test_bin_clean_nf <- test_bin_nf %>%
  filter(if_all(all_of(predictor_vars), ~ !is.na(.) & is.finite(.)))

# Predict probabilities
predict_prob_nf <- predict(randForMod_nf, newdata = test_bin_clean_nf, type = "prob")

# Convert ECIG_BINARY to numeric labels (0 or 1)
weights_nf <- as.numeric(as.character(test_bin_clean_nf$ECIG_BINARY) == "1")

# Combine and drop NAs
pr_data_nf <- data.frame(prob = predict_prob_nf[, 2], label = weights_nf)
pr_data_nf <- pr_data_nf[complete.cases(pr_data_nf), ]

# Run PR Curve
pr_nf <- pr.curve(scores.class0 = pr_data_nf$prob,
               weights.class0 = pr_data_nf$label,
               curve = TRUE)

# Plot it
plot(pr_nf)

pr_nf$auc.integral  # This is your PR-AUC score
```
Multi-Class Logistic Regression Model

# Class Imbalance Check Multi Class
```{r}
set.seed(124)
brfss_2017_cleaned$ECIG_COMP <- as.factor(brfss_2017_cleaned$ECIG_COMP)
split_lr <- createDataPartition(brfss_2017_cleaned$ECIG_COMP, times = 1, p = 0.7, list = FALSE)
train_lr <- brfss_2017_cleaned[split_lr, ]
test_lr <- brfss_2017_cleaned[-split_lr, ]

ggplot(train_lr, aes(x = as.factor(ECIG_COMP), fill = as.factor(ECIG_COMP))) + 
    geom_bar() + 
    scale_x_discrete(labels = c('Everyday', 'Some Days', 'Former', 'Never Used')) + 
    labs(title = "Class Proportions for E-Cigarette Smoking Status", x = "E-Cig Smoking Status")
```


# Predictor Variables
```{r}
predictor_vars <- c('AGE80', 'BMI', 'SMOKER_COMP', 'STATE', 'ADDEPEV', 'ALCDAY5',
                    'CHCCOPD', 'CHECKUP', 'EDUCA', 'GENHLTH', 'HLTHPLN', 'INCOME', 'SEX')
```


# Train-Test Split for Multi Class
```{r}
set.seed(124)
#split <- sample(nrow(brfss_2017_cleaned), 0.6 * nrow(brfss_2017_cleaned))
# Multiclass factorization
brfss_2017_cleaned$ECIG_COMP <- as.factor(brfss_2017_cleaned$ECIG_COMP)
split <- createDataPartition(brfss_2017_cleaned$ECIG_COMP, times = 1, p = .7, list = FALSE)
train <- brfss_2017_cleaned[split, ]
test <- brfss_2017_cleaned[-split, ]
```

# Model Fitting (Ordinal Logistic Regression)
```{r}
x_train <- data.matrix(train[, predictor_vars])
y_train <- train$ECIG_COMP

# Create predictor matrix
x <- data.matrix(train_bin[, predictors])

# Target
y <- train_bin$ECIG_BINARY

# Final modeling data frame
data <- data.frame(x, y)

# Revalue factor levels
y_train <- revalue(y_train, c("1" = "X1", "2" = "X2", "3" = "X3", "4" = "X4"))
levels(y_train)

# Combine x_train and y_train into one data frame
train_lm <- data.frame(y_train, x_train)

set.seed(123)
model <- polr(y_train ~ ., data = train_lm)
model
```
```{r}
summary(model)
model_parameters(model)
vif(model)
```

Stratified K-Fold & SMOTE
```{r}
train_lm <- train_lm[complete.cases(train_lm), ]

set.seed(12)
ctrl <- trainControl(method = "cv", #cross validation
                     number = 10, # 10 folds
                     sampling = "smote",
                     classProbs = TRUE,
                     summaryFunction = multiClassSummary)
ordLogMod <- train(y_train ~ .,
                       data = train_lm,
                       method = "polr",
                       trControl = ctrl)
ordLogMod
```
```{r}
#plot(ordLogMod$resample.)
```
```{r}
#confint(model)
```


Test Data Predictions
```{r}
predict_classes <- predict(model, test)
head(predict_classes)
```
```{r}
predict_prob <- predict(model, test, type = "p")
head(predict_prob)
```
```{r}
table(test$ECIG_COMP, predict_classes)
```
```{r}
#mean(as.character(test$ECIG_COMP) != as.character(predict_classes$))
```
